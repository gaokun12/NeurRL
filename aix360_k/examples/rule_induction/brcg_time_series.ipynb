{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, balanced_accuracy_score\n",
    "from aix360.algorithms.rule_induction.rbm.boolean_rule_cg import BooleanRuleCG as BRCG\n",
    "from aix360.algorithms.rbm import FeatureBinarizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule Induction using BRCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification with a random 20% test set\n",
    "\n",
    "We read the adult dataset from the UCI repository. The goal is to learn a rule describing people who earn more than 50K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../rule_injection_embed/data/full_features/low.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comlum names shall not contain whitespace or arithmetic operators (+, -, *, /)\n",
    "We eventually output the rule set in TRXF format, where compound features are supported by parsing an expression string. So simple features like column names of a data frame must not contain these so that they are parsed as a single variable rather than an expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24287 entries, 0 to 24286\n",
      "Columns: 133 entries, glucose_t0_24_t0_22hours to label\n",
      "dtypes: float64(133)\n",
      "memory usage: 24.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.columns = df.columns.str.replace('-', '_')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   glucose_t0_24_t0_22hours  glucose_t0_22_t0_20hours  \\\n",
      "0                      10.8                       8.8   \n",
      "1                       NaN                      10.8   \n",
      "2                       NaN                       NaN   \n",
      "3                       NaN                      10.5   \n",
      "4                       NaN                       NaN   \n",
      "\n",
      "   glucose_t0_20_t0_18hours  glucose_t0_18_t0_16hours  \\\n",
      "0                       NaN                       NaN   \n",
      "1                       NaN                       NaN   \n",
      "2                       6.3                       NaN   \n",
      "3                       9.4                       NaN   \n",
      "4                      10.4                       NaN   \n",
      "\n",
      "   glucose_t0_16_t0_14hours  glucose_t0_14_t0_12hours  \\\n",
      "0                       7.7                       NaN   \n",
      "1                       7.2                       NaN   \n",
      "2                       6.7                       NaN   \n",
      "3                      12.1                       NaN   \n",
      "4                       8.2                      11.2   \n",
      "\n",
      "   glucose_t0_12_t0_10hours  glucose_t0_10_t0_8hours  glucose_t0_8_t0_6hours  \\\n",
      "0                      14.8                      NaN                     NaN   \n",
      "1                      14.5                    19.25                     NaN   \n",
      "2                       5.2                     4.60                     NaN   \n",
      "3                      16.4                      NaN                     NaN   \n",
      "4                       NaN                    10.80                     NaN   \n",
      "\n",
      "   glucose_t0_6_t0_4hours  ...  future_insulin_group5_t0+6_t0+8hours  \\\n",
      "0                     NaN  ...                                   0.0   \n",
      "1                     NaN  ...                                   0.0   \n",
      "2                     6.4  ...                                   0.0   \n",
      "3                     NaN  ...                                   0.0   \n",
      "4                     NaN  ...                                   0.0   \n",
      "\n",
      "   future_insulin_group5_t0+8_t0+10hours  \\\n",
      "0                                    0.0   \n",
      "1                                    0.0   \n",
      "2                                    0.0   \n",
      "3                                    0.0   \n",
      "4                                    0.0   \n",
      "\n",
      "   future_insulin_group5_t0+10_t0+12hours  \\\n",
      "0                                     0.0   \n",
      "1                                     0.0   \n",
      "2                                     0.0   \n",
      "3                                     0.0   \n",
      "4                                     0.0   \n",
      "\n",
      "   future_insulin_group5_t0+12_t0+14hours  \\\n",
      "0                                     0.0   \n",
      "1                                     0.0   \n",
      "2                                     0.0   \n",
      "3                                     0.0   \n",
      "4                                     0.0   \n",
      "\n",
      "   future_insulin_group5_t0+14_t0+16hours  \\\n",
      "0                                     0.0   \n",
      "1                                     0.0   \n",
      "2                                     0.0   \n",
      "3                                     0.0   \n",
      "4                                     0.0   \n",
      "\n",
      "   future_insulin_group5_t0+16_t0+18hours  \\\n",
      "0                                     0.0   \n",
      "1                                     0.0   \n",
      "2                                     0.0   \n",
      "3                                     0.0   \n",
      "4                                     0.0   \n",
      "\n",
      "   future_insulin_group5_t0+18_t0+20hours  \\\n",
      "0                                     0.0   \n",
      "1                                     0.0   \n",
      "2                                     0.0   \n",
      "3                                     0.0   \n",
      "4                                     0.0   \n",
      "\n",
      "   future_insulin_group5_t0+20_t0+22hours  \\\n",
      "0                                     0.0   \n",
      "1                                     0.0   \n",
      "2                                     0.0   \n",
      "3                                     0.0   \n",
      "4                                     0.0   \n",
      "\n",
      "   future_insulin_group5_t0+22_t0+24hours  label  \n",
      "0                                     0.0    0.0  \n",
      "1                                     0.0    0.0  \n",
      "2                                     0.0    0.0  \n",
      "3                                     0.0    0.0  \n",
      "4                                     0.0    0.0  \n",
      "\n",
      "[5 rows x 133 columns]\n"
     ]
    }
   ],
   "source": [
    "TARGET_COLUMN = 'label'\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rule induction trains for specific 'foreground' aka 'positive' value of the target label, which we set to '>50K' below. This means that the rule set will characterize the set of adults who earn more than 50K)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive value 1.0 occurs 2378 times.\n",
      "0.0    21909\n",
      "1.0     2378\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "POS_VALUE = 1.0 # Setting positive value of the label for which we train\n",
    "values_dist = df[TARGET_COLUMN].value_counts()\n",
    "print('Positive value {} occurs {} times.'.format(POS_VALUE,values_dist[POS_VALUE]))\n",
    "print(values_dist)\n",
    "# This is distribution of the two values of the target label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    2378\n",
      "1.0    2378\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glucose_t0_24_t0_22hours</th>\n",
       "      <th>glucose_t0_22_t0_20hours</th>\n",
       "      <th>glucose_t0_20_t0_18hours</th>\n",
       "      <th>glucose_t0_18_t0_16hours</th>\n",
       "      <th>glucose_t0_16_t0_14hours</th>\n",
       "      <th>glucose_t0_14_t0_12hours</th>\n",
       "      <th>glucose_t0_12_t0_10hours</th>\n",
       "      <th>glucose_t0_10_t0_8hours</th>\n",
       "      <th>glucose_t0_8_t0_6hours</th>\n",
       "      <th>glucose_t0_6_t0_4hours</th>\n",
       "      <th>...</th>\n",
       "      <th>future_insulin_group5_t0+6_t0+8hours</th>\n",
       "      <th>future_insulin_group5_t0+8_t0+10hours</th>\n",
       "      <th>future_insulin_group5_t0+10_t0+12hours</th>\n",
       "      <th>future_insulin_group5_t0+12_t0+14hours</th>\n",
       "      <th>future_insulin_group5_t0+14_t0+16hours</th>\n",
       "      <th>future_insulin_group5_t0+16_t0+18hours</th>\n",
       "      <th>future_insulin_group5_t0+18_t0+20hours</th>\n",
       "      <th>future_insulin_group5_t0+20_t0+22hours</th>\n",
       "      <th>future_insulin_group5_t0+22_t0+24hours</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.9</td>\n",
       "      <td>14.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.8</td>\n",
       "      <td>13.3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.3</td>\n",
       "      <td>10.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   glucose_t0_24_t0_22hours  glucose_t0_22_t0_20hours  \\\n",
       "0                       NaN                      11.0   \n",
       "1                       NaN                       5.0   \n",
       "2                       NaN                       5.7   \n",
       "3                       NaN                      13.6   \n",
       "4                       9.9                      11.3   \n",
       "\n",
       "   glucose_t0_20_t0_18hours  glucose_t0_18_t0_16hours  \\\n",
       "0                      10.7                       NaN   \n",
       "1                       NaN                       NaN   \n",
       "2                       NaN                       8.3   \n",
       "3                       NaN                       NaN   \n",
       "4                       NaN                       6.5   \n",
       "\n",
       "   glucose_t0_16_t0_14hours  glucose_t0_14_t0_12hours  \\\n",
       "0                       NaN                      11.4   \n",
       "1                       7.9                       NaN   \n",
       "2                      10.3                       NaN   \n",
       "3                       8.7                       NaN   \n",
       "4                       NaN                       5.1   \n",
       "\n",
       "   glucose_t0_12_t0_10hours  glucose_t0_10_t0_8hours  glucose_t0_8_t0_6hours  \\\n",
       "0                       NaN                     12.9                    14.7   \n",
       "1                       NaN                     18.8                    13.3   \n",
       "2                       NaN                     11.4                     NaN   \n",
       "3                       7.6                      NaN                     NaN   \n",
       "4                       NaN                      NaN                     9.8   \n",
       "\n",
       "   glucose_t0_6_t0_4hours  ...  future_insulin_group5_t0+6_t0+8hours  \\\n",
       "0                     NaN  ...                                   0.0   \n",
       "1                    13.3  ...                                   0.0   \n",
       "2                     NaN  ...                                   0.0   \n",
       "3                     NaN  ...                                   0.0   \n",
       "4                     NaN  ...                                   0.0   \n",
       "\n",
       "   future_insulin_group5_t0+8_t0+10hours  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                   20.0   \n",
       "\n",
       "   future_insulin_group5_t0+10_t0+12hours  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "\n",
       "   future_insulin_group5_t0+12_t0+14hours  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "\n",
       "   future_insulin_group5_t0+14_t0+16hours  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "\n",
       "   future_insulin_group5_t0+16_t0+18hours  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "\n",
       "   future_insulin_group5_t0+18_t0+20hours  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "\n",
       "   future_insulin_group5_t0+20_t0+22hours  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "\n",
       "   future_insulin_group5_t0+22_t0+24hours  label  \n",
       "0                                     0.0    0.0  \n",
       "1                                     0.0    1.0  \n",
       "2                                     0.0    0.0  \n",
       "3                                     0.0    1.0  \n",
       "4                                    26.0    0.0  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choolse all positive data \n",
    "df_positive = df[df[TARGET_COLUMN] == POS_VALUE]\n",
    "df_negative = df[df[TARGET_COLUMN] != POS_VALUE]\n",
    "# random choose negative data\n",
    "df_negative = df_negative.sample(n = len(df_positive))\n",
    "df = pd.concat([df_positive, df_negative])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "print(df[TARGET_COLUMN].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split and encode labels as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "0.0    17538\n",
      "1.0     1891\n",
      "Name: label, dtype: int64\n",
      "Test set:\n",
      "0.0    4371\n",
      "1.0     487\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# Split the data set into 80% training and 20% test set\n",
    "print('Training set:')\n",
    "print(train[TARGET_COLUMN].value_counts())\n",
    "print('Test set:')\n",
    "print(test[TARGET_COLUMN].value_counts())\n",
    "\n",
    "y_train = train[TARGET_COLUMN].apply(lambda x: 1 if x == POS_VALUE else 0)\n",
    "x_train = train.drop(columns=[TARGET_COLUMN])\n",
    "\n",
    "y_test = test[TARGET_COLUMN].apply(lambda x: 1 if x == POS_VALUE else 0)\n",
    "x_test = test.drop(columns=[TARGET_COLUMN])\n",
    "# Split data frames into features and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the BRCG explainer and train it using default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaokun/kk/AIX360/aix360/algorithms/rbm/features.py:141: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  A[colName] = data[c].map(maps[c]).astype(int)\n",
      "/home/gaokun/kk/AIX360/aix360/algorithms/rbm/features.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  A[(str(c), '==', str(maps[c].index[0]))] = 1 - A[colName]\n",
      "/home/gaokun/kk/AIX360/aix360/algorithms/rbm/features.py:141: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  A[colName] = data[c].map(maps[c]).astype(int)\n",
      "/home/gaokun/kk/AIX360/aix360/algorithms/rbm/features.py:143: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  A[(str(c), '==', str(maps[c].index[0]))] = 1 - A[colName]\n"
     ]
    },
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m fb \u001b[38;5;241m=\u001b[39m FeatureBinarizer(negations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m X_train_fb \u001b[38;5;241m=\u001b[39m fb\u001b[38;5;241m.\u001b[39mfit_transform(x_train)\n\u001b[0;32m----> 3\u001b[0m x_test_fb \u001b[38;5;241m=\u001b[39m \u001b[43mfb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m explainer \u001b[38;5;241m=\u001b[39m BRCG(silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/kk/AIX360/aix360/algorithms/rbm/features.py:141\u001b[0m, in \u001b[0;36mFeatureBinarizer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m maps:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# Rename values to 0, 1\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     colName \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mstr\u001b[39m(c), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m!=\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(maps[c]\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m])) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(maps[c]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mstr\u001b[39m(c), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m==\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(maps[c]\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m--> 141\u001b[0m     A[colName] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnegations:\n\u001b[1;32m    143\u001b[0m         A[(\u001b[38;5;28mstr\u001b[39m(c), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m==\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(maps[c]\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m]))] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m A[colName]\n",
      "File \u001b[0;32m~/anaconda3/envs/newtf/lib/python3.11/site-packages/pandas/core/generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6233\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   6235\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m   6236\u001b[0m     ]\n\u001b[1;32m   6238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6239\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6240\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6243\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/newtf/lib/python3.11/site-packages/pandas/core/internals/managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dtype, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/newtf/lib/python3.11/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m~/anaconda3/envs/newtf/lib/python3.11/site-packages/pandas/core/internals/blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    524\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 526\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    529\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m~/anaconda3/envs/newtf/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/newtf/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    227\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/newtf/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:140\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot astype a timedelta from [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] to [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating) \u001b[38;5;129;01mand\u001b[39;00m is_integer_dtype(dtype):\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# then coerce to a proper dtype and recall astype_nansafe\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_datetime64_dtype(dtype):\n",
      "File \u001b[0;32m~/anaconda3/envs/newtf/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(values)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    184\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "fb = FeatureBinarizer(negations=True)\n",
    "X_train_fb = fb.fit_transform(x_train)\n",
    "x_test_fb = fb.transform(x_test)\n",
    "\n",
    "explainer = BRCG(silent=True)\n",
    "start_time = time.time()\n",
    "explainer.fit(X_train_fb, y_train)\n",
    "end_time = time.time()\n",
    "print('Training time (sec): ' + str(end_time - start_time))\n",
    "\n",
    "# compute performance metrics on test set\n",
    "y_pred = explainer.predict(x_test_fb)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Balanced accuracy:', balanced_accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, pos_label=1))\n",
    "print('Recall:', recall_score(y_test, y_pred, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the rule set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if\n",
      "false\n",
      "then\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "trxf_ruleset = explainer.explain()\n",
    "print(str(trxf_ruleset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the resulting ruleset to a PMML file\n",
    "### Construct a RuleSetClassifier object\n",
    "A rule set by itself is merely a description of the given concept/target. Therefore, to use rule sets for a binary classification task, we must specify how to deal with potential overlaps between rule sets. For example, we could have learned 2 rule sets: one for >50K and another for <=50K. For instances where both rule sets are triggered, how do we classify that instance? There are 3 rule selection methods supported in PMML: First Hit, Weighted Sum, and Weighted Max. See here for more info: https://dmg.org/pmml/v4-4/RuleSet.html#xsdElement_RuleSelectionMethod. If we only learn a rule set for a single label, we can set a default label to which instances will be classified when the learned rule set does not trigger. \n",
    "\n",
    "In our case, since we only learn a rule set for a single label and use the default label for the rest, all 3 rule selection methods will have the same effect. However, if a rule selection method other than FirstHit is chosen, we need to compute the weights and confidence values for each rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aix360.algorithms.rule_induction.trxf.classifier.ruleset_classifier as trxf_classifier\n",
    "import aix360.algorithms.rule_induction.trxf.pmml_export as pmml\n",
    "classifier = trxf_classifier.RuleSetClassifier([trxf_ruleset],\n",
    "                                               rule_selection_method=trxf_classifier.RuleSelectionMethod.WEIGHTED_MAX,\n",
    "                                               confidence_metric=trxf_classifier.ConfidenceMetric.LAPLACE,\n",
    "                                               weight_metric=trxf_classifier.WeightMetric.CONFIDENCE,\n",
    "                                               default_label='<=50K')\n",
    "classifier.update_rules_with_metrics(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the TRXF classifier to a PMML document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pmml.TrxfReader()\n",
    "reader.load_data_dictionary(x_test)\n",
    "serializer = pmml.NyokaSerializer()\n",
    "exporter = pmml.PmmlExporter(reader, serializer)\n",
    "with open(\"adult_weighted_max_brcg.pmml\", \"w\") as text_file:\n",
    "    text_file.write(exporter.export(classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28197</th>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>287008.0</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13925</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>93056.0</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age workclass    fnlwgt    education  education_num  \\\n",
       "28197  40.0   Private  287008.0  Prof-school           15.0   \n",
       "13925  33.0   Private   93056.0      7th-8th            4.0   \n",
       "\n",
       "           marital_status         occupation relationship   race   sex  \\\n",
       "28197  Married-civ-spouse     Prof-specialty      Husband  White  Male   \n",
       "13925            Divorced  Handlers-cleaners    Own-child  White  Male   \n",
       "\n",
       "       capital_gain  capital_loss  hours_per_week native_country  \n",
       "28197       15024.0           0.0            55.0        Germany  \n",
       "13925           0.0           0.0            40.0  United-States  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first row of x_test\n",
    "ele = x_test.iloc[100:102]\n",
    "ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
